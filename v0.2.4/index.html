<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · CSV.jl</title><link rel="canonical" href="https://juliadata.github.io/CSV.jl/stable/index.html"/><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>CSV.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href="index.html">Home</a><ul class="internal"><li><a class="toctext" href="#High-level-interface-1">High-level interface</a></li><li><a class="toctext" href="#Lower-level-utilities-1">Lower-level utilities</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href="index.html">Home</a></li></ul><a class="edit-page" href="https://github.com/JuliaData/CSV.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="CSV.jl-Documentation-1" href="#CSV.jl-Documentation-1">CSV.jl Documentation</a></h1><p>CSV.jl is built to be a fast and flexible pure-Julia library for handling delimited text files.</p><ul><li><a href="index.html#CSV.jl-Documentation-1">CSV.jl Documentation</a></li><ul><li><a href="index.html#High-level-interface-1">High-level interface</a></li><li><a href="index.html#Lower-level-utilities-1">Lower-level utilities</a></li></ul></ul><h2><a class="nav-anchor" id="High-level-interface-1" href="#High-level-interface-1">High-level interface</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.read" href="#CSV.read"><code>CSV.read</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>CSV.read(fullpath::Union{AbstractString,IO}, sink::Type{T}=DataFrame, args...; kwargs...)</code> =&gt; <code>typeof(sink)</code></p><p><code>CSV.read(fullpath::Union{AbstractString,IO}, sink::Data.Sink; kwargs...)</code> =&gt; <code>Data.Sink</code></p><p>parses a delimited file into a Julia structure (a DataFrame by default, but any valid <code>Data.Sink</code> may be requested).</p><p>Minimal error-reporting happens w/ <code>CSV.read</code> for performance reasons; for problematic csv files, try <a href="index.html#CSV.validate"><code>CSV.validate</code></a> which takes exact same arguments as <code>CSV.read</code> and provides much more information for why reading the file failed.</p><p>Positional arguments:</p><ul><li><p><code>fullpath</code>; can be a file name (string) or other <code>IO</code> instance</p></li><li><p><code>sink::Type{T}</code>; <code>DataFrame</code> by default, but may also be other <code>Data.Sink</code> types that support streaming via <code>Data.Field</code> interface; note that the method argument can be the <em>type</em> of <code>Data.Sink</code>, plus any required arguments the sink may need (<code>args...</code>).                   or an already constructed <code>sink</code> may be passed (2nd method above)</p></li></ul><p>Keyword Arguments:</p><ul><li><p><code>delim::Union{Char,UInt8}</code>: how fields in the file are delimited; default <code>&#39;,&#39;</code></p></li><li><p><code>quotechar::Union{Char,UInt8}</code>: the character that indicates a quoted field that may contain the <code>delim</code> or newlines; default <code>&#39;&quot;&#39;</code></p></li><li><p><code>escapechar::Union{Char,UInt8}</code>: the character that escapes a <code>quotechar</code> in a quoted field; default <code>&#39;\&#39;</code></p></li><li><p><code>missingstring::String</code>: indicates how missing values are represented in the dataset; default <code>&quot;&quot;</code></p></li><li><p><code>dateformat::Union{AbstractString,Dates.DateFormat}</code>: how dates/datetimes are represented in the dataset; default <code>Base.Dates.ISODateTimeFormat</code></p></li><li><p><code>decimal::Union{Char,UInt8}</code>: character to recognize as the decimal point in a float number, e.g. <code>3.14</code> or <code>3,14</code>; default <code>&#39;.&#39;</code></p></li><li><p><code>truestring</code>: string to represent <code>true::Bool</code> values in a csv file; default <code>&quot;true&quot;</code>. Note that <code>truestring</code> and <code>falsestring</code> cannot start with the same character.</p></li><li><p><code>falsestring</code>: string to represent <code>false::Bool</code> values in a csv file; default <code>&quot;false&quot;</code></p></li><li><p><code>header</code>: column names can be provided manually as a complete Vector{String}, or as an Int/AbstractRange which indicates the row/rows that contain the column names</p></li><li><p><code>datarow::Int</code>: specifies the row on which the actual data starts in the file; by default, the data is expected on the next row after the header row(s); for a file without column names (header), specify <code>datarow=1</code></p></li><li><p><code>types</code>: column types can be provided manually as a complete Vector{Type}, or in a Dict to reference individual columns by name or number</p></li><li><p><code>allowmissing::Symbol=:all</code>: indicates whether columns should allow for missing values or not, that is whether their element type should be <code>Union{T,Missing}</code>; by default, all columns are allowed to contain missing values. If set to <code>:none</code>, no column can contain missing values, and if set to <code>:auto</code>, only colums which contain missing values in the first <code>rows_for_type_detect</code> rows are allowed to contain missing values. Column types specified via <code>types</code> are not affected by this argument.</p></li><li><p><code>footerskip::Int</code>: indicates the number of rows to skip at the end of the file</p></li><li><p><code>rows_for_type_detect::Int=100</code>: indicates how many rows should be read to infer the types of columns</p></li><li><p><code>rows::Int</code>: indicates the total number of rows to read from the file; by default the file is pre-parsed to count the # of rows; <code>-1</code> can be passed to skip a full-file scan, but the <code>Data.Sink</code> must be set up to account for a potentially unknown # of rows</p></li><li><p><code>use_mmap::Bool=true</code>: whether the underlying file will be mmapped or not while parsing; note that on Windows machines, the underlying file will not be &quot;deletable&quot; until Julia GC has run (can be run manually via <code>gc()</code>) due to the use of a finalizer when reading the file.</p></li><li><p><code>append::Bool=false</code>: if the <code>sink</code> argument provided is an existing table, <code>append=true</code> will append the source&#39;s data to the existing data instead of doing a full replace</p></li><li><p><code>transforms::Dict{Union{String,Int},Function}</code>: a Dict of transforms to apply to values as they are parsed. Note that a column can be specified by either number or column name.</p></li><li><p><code>transpose::Bool=false</code>: when reading the underlying csv data, rows should be treated as columns and columns as rows, thus the resulting dataset will be the &quot;transpose&quot; of the actual csv data.</p></li><li><p><code>categorical::Bool=true</code>: read string column as a <code>CategoricalArray</code> (<a href="https://github.com/JuliaData/CategoricalArrays.jl">ref</a>), as long as the % of unique values seen during type detection is less than 67%. This will dramatically reduce memory use in cases where the number of unique values is small.</p></li><li><p><code>weakrefstrings::Bool=true</code>: whether to use <a href="https://github.com/quinnj/WeakRefStrings.jl"><code>WeakRefStrings</code></a> package to speed up file parsing; can only be <code>=true</code> for the <code>Sink</code> objects that support <code>WeakRefStringArray</code> columns. Note that <code>WeakRefStringArray</code> still returns regular <code>String</code> elements.</p></li></ul><p>Example usage:</p><pre><code class="language-none">julia&gt; dt = CSV.read(&quot;bids.csv&quot;)
7656334×9 DataFrames.DataFrame
│ Row     │ bid_id  │ bidder_id                               │ auction │ merchandise      │ device      │
├─────────┼─────────┼─────────────────────────────────────────┼─────────┼──────────────────┼─────────────┤
│ 1       │ 0       │ &quot;8dac2b259fd1c6d1120e519fb1ac14fbqvax8&quot; │ &quot;ewmzr&quot; │ &quot;jewelry&quot;        │ &quot;phone0&quot;    │
│ 2       │ 1       │ &quot;668d393e858e8126275433046bbd35c6tywop&quot; │ &quot;aeqok&quot; │ &quot;furniture&quot;      │ &quot;phone1&quot;    │
│ 3       │ 2       │ &quot;aa5f360084278b35d746fa6af3a7a1a5ra3xe&quot; │ &quot;wa00e&quot; │ &quot;home goods&quot;     │ &quot;phone2&quot;    │
...</code></pre><p>Other example invocations may include:</p><pre><code class="language-julia"># read in a tab-delimited file
CSV.read(file; delim=&#39;	&#39;)

# read in a comma-delimited file with missing values represented as &#39;\N&#39;, such as a MySQL export
CSV.read(file; missingstring=&quot;\N&quot;)

# read a csv file that happens to have column names in the first column, and grouped data in rows instead of columns
CSV.read(file; transpose=true)

# manually provided column names; must match # of columns of data in file
# this assumes there is no header row in the file itself, so data parsing will start at the very beginning of the file
CSV.read(file; header=[&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;])

# manually provided column names, even though the file itself has column names on the first row
# `datarow` is specified to ensure data parsing occurs at correct location
CSV.read(file; header=[&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;], datarow=2)

# types provided manually; as a vector, must match length of columns in actual data
CSV.read(file; types=[Int, Int, Float64])

# types provided manually; as a Dict, can specify columns by # or column name
CSV.read(file; types=Dict(3=&gt;Float64, 6=&gt;String))
CSV.read(file; types=Dict(&quot;col3&quot;=&gt;Float64, &quot;col6&quot;=&gt;String))

# manually provided # of rows; if known beforehand, this will improve parsing speed
# this is also a way to limit the # of rows to be read in a file if only a sample is needed
CSV.read(file; rows=10000)

# for data files, `file` and `file2`, with the same structure, read both into a single DataFrame
# note that `df` is used as a 2nd argument in the 2nd call to `CSV.read` and the keyword argument
# `append=true` is passed
df = CSV.read(file)
df = CSV.read(file2, df; append=true)

# manually construct a `CSV.Source` once, then stream its data to both a DataFrame
# and SQLite table `sqlite_table` in the SQLite database `db`
# note the use of `CSV.reset!` to ensure the `source` can be streamed from again
source = CSV.Source(file)
df1 = CSV.read(source, DataFrame)
CSV.reset!(source)
db = SQLite.DB()
sq1 = CSV.read(source, SQLite.Sink, db, &quot;sqlite_table&quot;)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/blob/e4962ba3756d7488a566ab618209fa927ed2f730/src/Source.jl#L237-L334">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.validate" href="#CSV.validate"><code>CSV.validate</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>CSV.validate(fullpath::Union{AbstractString,IO}, sink::Type{T}=DataFrame, args...; kwargs...)</code> =&gt; <code>typeof(sink)</code></p><p><code>CSV.validate(fullpath::Union{AbstractString,IO}, sink::Data.Sink; kwargs...)</code> =&gt; <code>Data.Sink</code></p><p>Takes the same positional &amp; keyword arguments as <a href="index.html#CSV.read"><code>CSV.read</code></a>, but provides detailed information as to why reading a csv file failed. Useful for cases where reading fails and it&#39;s not clear whether it&#39;s due to a row havign too many columns, or wrong types, or what have you.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/blob/e4962ba3756d7488a566ab618209fa927ed2f730/src/validate.jl#L14-L21">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.write" href="#CSV.write"><code>CSV.write</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>CSV.write(file_or_io::Union{AbstractString,IO}, source::Type{T}, args...; kwargs...)</code> =&gt; <code>CSV.Sink</code></p><p><code>CSV.write(file_or_io::Union{AbstractString,IO}, source::Data.Source; kwargs...)</code> =&gt; <code>CSV.Sink</code></p><p>write a <code>Data.Source</code> out to a <code>file_or_io</code>.</p><p>Positional Arguments:</p><ul><li><p><code>file_or_io</code>; can be a file name (string) or other <code>IO</code> instance</p></li><li><p><code>source</code> can be the <em>type</em> of <code>Data.Source</code>, plus any required <code>args...</code>, or an already constructed <code>Data.Source</code> can be passsed in directly (2nd method)</p></li></ul><p>Keyword Arguments:</p><ul><li><p><code>delim::Union{Char,UInt8}</code>; how fields in the file will be delimited; default is <code>UInt8(&#39;,&#39;)</code></p></li><li><p><code>quotechar::Union{Char,UInt8}</code>; the character that indicates a quoted field that may contain the <code>delim</code> or newlines; default is <code>UInt8(&#39;&quot;&#39;)</code></p></li><li><p><code>escapechar::Union{Char,UInt8}</code>; the character that escapes a <code>quotechar</code> in a quoted field; default is <code>UInt8(&#39;\&#39;)</code></p></li><li><p><code>missingstring::String</code>; the ascii string that indicates how missing values will be represented in the dataset; default is the empty string <code>&quot;&quot;</code></p></li><li><p><code>dateformat</code>; how dates/datetimes will be represented in the dataset; default is ISO-8601 <code>yyyy-mm-ddTHH:MM:SS.s</code></p></li><li><p><code>header::Bool</code>; whether to write out the column names from <code>source</code></p></li><li><p><code>colnames::Vector{String}</code>; a vector of string column names to be used when writing the header row</p></li><li><p><code>append::Bool</code>; start writing data at the end of <code>io</code>; by default, <code>io</code> will be reset to the beginning or overwritten before writing</p></li><li><p><code>transforms::Dict{Union{String,Int},Function}</code>; a Dict of transforms to apply to values as they are parsed. Note that a column can be specified by either number or column name.</p></li></ul><p>A few example invocations include:</p><pre><code class="language-julia"># write out a DataFrame `df` to a file name &quot;out.csv&quot; with all defaults, including comma as delimiter
CSV.write(&quot;out.csv&quot;, df)

# write out a DataFrame, this time as a tab-delimited file
CSV.write(&quot;out.csv&quot;, df; delim=&#39;	&#39;)

# write out a DataFrame, with missing values represented by the string &quot;NA&quot;
CSV.write(&quot;out.csv&quot;, df; missingstring=&quot;NA&quot;)

# write out a &quot;header-less&quot; file, with actual data starting on row 1
CSV.write(&quot;out.csv&quot;, df; header=false)

# write out a DataFrame `df` twice to a file, the resulting file with have twice the # of rows as the DataFrame
# note the usage of the keyword argument `append=true` in the 2nd call
CSV.write(&quot;out.csv&quot;, df)
CSV.write(&quot;out.csv&quot;, df; append=true)

# write a DataFrame out to an IOBuffer instead of a file
io = IOBuffer
CSV.write(io, df)

# write the result of an SQLite query out to a comma-delimited file
db = SQLite.DB()
sqlite_source = SQLite.Source(db, &quot;select * from sqlite_table&quot;)
CSV.write(&quot;sqlite_table.csv&quot;, sqlite_source)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/blob/e4962ba3756d7488a566ab618209fa927ed2f730/src/Sink.jl#L75-L128">source</a></section><h2><a class="nav-anchor" id="Lower-level-utilities-1" href="#Lower-level-utilities-1">Lower-level utilities</a></h2><pre><code class="language-none">CSV.Source
CSV.Sink
CSV.Options
CSV.parsefield
CSV.readline
CSV.readsplitline
CSV.countlines</code></pre><footer><hr/></footer></article></body></html>
